{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoseLuckmann/skynet-tutorial/blob/main/SkynetOpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uma introdução as ferramentas do LLamaIndex + Google Gemini\n",
        "\n",
        "| | |\n",
        "|-|-|\n",
        "|Autor | [Zé Luckmann](https://github.com/JoseLuckmann) |"
      ],
      "metadata": {
        "id": "WJ5NphIySw7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "Este notebook serve para ilustrar de uma maneira simples como realizar a implementação de um React Agent usando a biblioteca LLamaIndex e o modelo GPT da OpenAI como motor de racicinio, um agente ReAct é um algoritmo que coordena o raciocínio e a ação, onde:\n",
        "*   O raciocínio é realizado pelo modelo de linguagem.\n",
        "*   O código da aplicação executa as ações, conforme as instruções do modelo de linguagem.\n",
        "\n",
        "Isso permite que problemas sejam resolvidos ao deixar o modelo 'pensar' nas tarefas passo a passo, tomando ações e recebendo feedback das ações antes de determinar os próximos passos.\n",
        "\n",
        "<div>\n",
        "    <table align=\"center\">\n",
        "      <tr><td>\n",
        "        <img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuuYg9Pduep9GkUfjloNVOiy3qjpPbT017GKlgGEGMaLNu_TCheEeJ7r8Qok6-0BK3KMfLvsN2vSgFQ8xOvnHM9CAb4Ix4I62bcN2oXFWfqAJzGAGbVqbeCyVktu3h9Dyf5ameRe54LEr32Emp0nG52iofpNOTXCxMY12K7fvmDZNPPmfJaT5zo1OBQA/s595/Screen%20Shot%202022-11-08%20at%208.53.49%20AM.png\" alt=\"The Reasoning and Acting Cycle\" width=\"500\" align=\"center\"/>\n",
        "      </td></tr>\n",
        "      <tr><td><div align=\"center\"><em>From the paper: <a href=\"https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/\">ReAct: Synergizing Reasoning and Acting in Language Models</a></em></div></td></tr>\n",
        "    </table>\n",
        "</div>\n",
        "\n",
        "Essa coordenação entre o modelo de linguagem e o ambiente é possibilitada ao solicitar que o modelo de linguagem comunique as ações pretendidas de forma específica e estruturada. A resposta é 'específica' no sentido de que a lista de possíveis ações são funções predefinidas e, portanto, necessariamente limitadas. A resposta também é 'estruturada', de forma que os parâmetros das funções fornecidos na resposta podem ser usados diretamente pelo código da aplicação, minimizando a necessidade de parsing, interpretação ou transformações adicionais.\n",
        "\n",
        "Ambos os requisitos podem ser suportados por muitos modelos de linguagem, pois são equivalentes a realizar tarefas de linguagem natural, como classificação e extração de informações. Como ilustrado nos dois primeiros exemplos deste notebook, a tarefa de identificar nomes de funções adequados e extrair parâmetros de função pode ser realizada apenas com prompt e parsing de resposta.\n",
        "\n",
        "Para garantir maior qualidade nas respostas de chamadas de função, em termos de validade, confiabilidade e consistência, muitos modelos agora possuem APIs integradas que suportam 'Chamada de Função' ou 'Chamada de Ferramentas' (esses termos frequentemente são usados de forma intercambiável). Esse suporte integrado reduz a quantidade de salvaguardas defensivas que um desenvolvedor precisa construir em torno do tratamento de respostas em suas aplicações."
      ],
      "metadata": {
        "id": "RnCsnOtaTUCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivos\n",
        "\n",
        "Para ilustrar os componentes básicos de chamadas de ferramentas e sua utilidade, este notebook demonstra a criação de um agente usando três tipos diferentes de ferramentas, da seguinte maneira:\n",
        "\n",
        "\n",
        "\n",
        "*   `FunctionTool` - para executar funções diretamente.\n",
        "*   `QueryEngineTool` com SQL - para consultas a bancos de dados.\n",
        "*   `QueryEngineTool` com Documentos - para consultas a documentos não estruturados.\n",
        "\n",
        "No primeiro exemplo, a lista de possíveis funções é fornecida a cada requisição, já que a API é sem estado (stateless). No segundo exemplo, o uso de um QueryEngine com SQL permite realizar consultas estruturadas em bancos de dados, enquanto no terceiro exemplo, o QueryEngine com Documentos permite realizar buscas e consultas em coleções de documentos. Esses exemplos demonstram como os diferentes tipos de ferramentas podem ser utilizados de maneira eficiente, destacando blocos de construção que podem ser adaptados para várias APIs de modelos e tecnologias.\n",
        "\n",
        "Os exemplos de chamadas de ferramenta visam explicar as bases para entender como interagir com APIs específicas. Para maximizar a produtividade e a confiabilidade das respostas, recomenda-se usar APIs que suportam chamadas de ferramentas e consultas estruturadas."
      ],
      "metadata": {
        "id": "dwKylctvUtvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Primeiros Passos"
      ],
      "metadata": {
        "id": "7TRLh8FOU--m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalar LLamaIndex\n",
        "\n",
        "Vamos instalar também as bibliotecas auxiliares para integração com OpenAI"
      ],
      "metadata": {
        "id": "fzwdN7NxVEXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q llama-index llama-index-llms-openai llama-index-embeddings-openai"
      ],
      "metadata": {
        "id": "-phg-vCJVE4o"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download dos dados para o exemplo"
      ],
      "metadata": {
        "id": "6Rmny-TYV1rF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf skynet-tutorial\n",
        "!git clone https://github.com/JoseLuckmann/skynet-tutorial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz6oBsIskhBZ",
        "outputId": "6afde4b8-817d-4c23-8fa0-d7d1606a9a0e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'skynet-tutorial'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 34 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (34/34), 376.07 KiB | 1.43 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurar informações da API da OpenAI\n",
        "\n",
        "Para começar a usar voce vai precisar de uma chave da OpenAI configurada no seu ambiente. Aqui no exemplo estamos mantendo a chave armazenada no Secrets do Colab"
      ],
      "metadata": {
        "id": "0mg05hCPQZoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI')"
      ],
      "metadata": {
        "id": "XnylRIkAx8P0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importações necessárias"
      ],
      "metadata": {
        "id": "dhruFBeMWLVA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3yi4g60Ue5DW"
      },
      "outputs": [],
      "source": [
        "#Utils\n",
        "import datetime\n",
        "from IPython.display import display, Markdown\n",
        "from sqlalchemy import create_engine\n",
        "#LLamaIndex\n",
        "from llama_index.core.agent import ReActAgent, FunctionCallingAgentWorker\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata, FunctionTool\n",
        "from llama_index.core.agent.react import ReActAgent\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings, PromptTemplate\n",
        "from llama_index.core.prompts.prompt_type import PromptType\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
        "from llama_index.core import SQLDatabase\n",
        "from llama_index.llms.openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "Settings.embed_model = OpenAIEmbedding()"
      ],
      "metadata": {
        "id": "FvKGvcE9vqnw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = Settings.llm.complete(\"What is (2+4)*20\")\n",
        "display(Markdown(str(response)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "-L9Ptm13Xpq9",
        "outputId": "1bdfd1e8-4cc1-419d-cdf9-27b2e3420915"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The answer is 120. \n\n(2 + 4) * 20 = 6 * 20 = 120"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparando o modelo com as configurações iniciais"
      ],
      "metadata": {
        "id": "iZPEq0dpWego"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste inicial do modelo"
      ],
      "metadata": {
        "id": "Oiaf_nV1Xd_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_letters(word):\n",
        "    \"\"\"Returns a dictionary with the count of each letter in 'word'.\"\"\"\n",
        "    return {letter: word.count(letter) for letter in set(word)}\n",
        "\n",
        "count_letters_tool = FunctionTool.from_defaults(fn=count_letters)\n",
        "\n",
        "tools = [count_letters_tool]"
      ],
      "metadata": {
        "id": "zDF-fhjRXW50"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent.from_tools(tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "5MBs_3M7XfCf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"How many r's have in strawberry\")\n",
        "display(Markdown(str(response)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "0-COewTBYPse",
        "outputId": "eb3274f7-7019-4d30-b5f3-7a6bbca4ab3d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 4624017f-1ddd-42b2-8d55-c3d03fda8c86. Step input: How many r's have in strawberry\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: count_letters\n",
            "Action Input: {'word': 'strawberry'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: {'s': 1, 'y': 1, 'e': 1, 't': 1, 'w': 1, 'a': 1, 'r': 3, 'b': 1}\n",
            "\u001b[0m> Running step 2aeaa5e6-5e64-4614-8a61-a0032c6f7149. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: There are 3 occurrences of the letter 'r' in the word \"strawberry\".\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "There are 3 occurrences of the letter 'r' in the word \"strawberry\"."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desenvolvendo funções da Skynet"
      ],
      "metadata": {
        "id": "_C4XhSMwXffs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmZX2_Y0e5Dh"
      },
      "source": [
        "### `QueryEngineTool` com Documentos\n",
        "\n",
        "Este código exemplifica a criação de um sistema de Recuperação de Informações Aumentada por Geração (RAG) usando um mecanismo de consulta baseado em vetores (VectorStoreIndex) para buscar informações em documentos não estruturados.\n",
        "\n",
        "#### Explicação do Código:\n",
        "\n",
        "1. **Leitura dos documentos**:\n",
        "   Aqui, o `SimpleDirectoryReader` é utilizado para carregar os dados dos documentos armazenados no diretório `./skynet-tutorial/data/targets/`. Esses documentos contêm informações sobre \"targets\" (alvos) que serão usados pelo modelo. Após a leitura, eles são armazenados na variável `target_docs`. Esse processo representa a fase de **ingestão de dados** no pipeline RAG, onde o sistema adquire os dados brutos que serão posteriormente indexados.\n",
        "\n",
        "2. **Criação de um índice vetorial**:\n",
        "   O `VectorStoreIndex` cria um índice vetorial a partir dos documentos carregados. Esse índice é essencial no contexto de **RAG** porque ele permite mapear os documentos para representações vetoriais (embeddings), facilitando a busca por similaridade. O índice vetorial é a base de mecanismos de recuperação baseados em vetores, onde consultas são convertidas em vetores, e a similaridade entre a consulta e os documentos no índice é calculada para retornar as respostas mais relevantes.\n",
        "\n",
        "3. **Conversão do índice em mecanismo de consulta**:\n",
        "   O método `as_query_engine()` transforma o índice vetorial em um **mecanismo de consulta**. Isso significa que agora temos uma interface que permite realizar consultas sobre o índice criado, buscando respostas com base em similaridade semântica. O mecanismo de consulta é uma parte fundamental de um sistema RAG, pois, ao invés de realizar consultas exatas ou baseadas em palavras-chave, ele permite consultas mais flexíveis que utilizam embeddings para encontrar documentos semântica e contextualmente relevantes.\n",
        "\n",
        "4. **Definição de QueryEngineTool**:\n",
        "   Nesta etapa, é criado um objeto `QueryEngineTool`, que encapsula o `target_engine` (mecanismo de consulta) em uma ferramenta específica. Ele inclui:\n",
        "   \n",
        "   - `query_engine`: O mecanismo de consulta que será usado para processar as consultas e retornar respostas baseadas na similaridade dos vetores.\n",
        "   - `metadata`: Um objeto `ToolMetadata` que contém informações sobre o nome e a descrição da ferramenta. A descrição informa que a ferramenta fornece informações sobre os alvos da Skynet, e é capaz de receber perguntas e retornar as respostas mais relevantes.\n",
        "\n",
        "#### Conceitos Fundamentais:\n",
        "\n",
        "- **RAG (Recuperação de Informação Aumentada por Geração)**: É uma técnica que combina recuperação de documentos com geração de linguagem natural. O componente de recuperação identifica documentos ou trechos relevantes, e o modelo gerador pode sintetizar ou reformular as respostas com base nesses documentos.\n",
        "\n",
        "- **Índice Vetorial**: Em vez de realizar buscas com base em palavras-chave, o índice vetorial mapeia documentos e consultas em um espaço vetorial, permitindo comparações baseadas em similaridade semântica. Esse tipo de abordagem é eficiente para consultas que buscam o significado mais geral e não correspondências exatas de palavras.\n",
        "\n",
        "- **QueryEngine**: O `QueryEngine` é a camada que permite a execução de consultas sobre um conjunto de dados indexados (neste caso, vetorialmente). Ele faz o trabalho de transformar a consulta de entrada em uma representação vetorial, comparar com os documentos já indexados, e retornar os mais relevantes.\n",
        "\n",
        "- **QueryEngineTool**: É uma abstração que organiza o mecanismo de consulta como uma \"ferramenta\". Ferramentas como essa são frequentemente usadas em arquiteturas de agentes inteligentes que precisam fazer consultas em diferentes tipos de fontes de dados (como bases de dados SQL, documentos, APIs, etc.) de maneira modular.\n",
        "\n",
        "Este pipeline permite consultas semânticas em uma base de documentos não estruturados, integrando técnicas de busca vetorial que são essenciais para sistemas de recuperação eficientes e dinâmicos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zJRtFKRMe5Di"
      },
      "outputs": [],
      "source": [
        "target_docs = SimpleDirectoryReader(input_dir=\"./skynet-tutorial/data/targets/\").load_data()\n",
        "target_index = VectorStoreIndex.from_documents(target_docs)\n",
        "target_engine = target_index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "EM-8vf8se5Dj"
      },
      "outputs": [],
      "source": [
        "target_query_engine = QueryEngineTool(\n",
        "        query_engine=target_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"targets\",\n",
        "            description=(\n",
        "                \"Provide information on Skynet's targets. Each document contains information about a potential target\"\n",
        "                \"It receives exactly the question as input and returns the most relevant answer.\"\n",
        "            ),\n",
        "        ),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CJSWV3Ne5Dj"
      },
      "source": [
        "# Terminators"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### `QueryEngineTool` com SQL\n",
        "\n",
        "Este trecho traz a criação de um mecanismo de consulta baseado em SQL para consultas em uma base de dados SQLite. O objetivo é fornecer uma interface que traduz consultas em linguagem natural para consultas SQL e retornar os dados desejados.\n",
        "\n",
        "#### Explicação do Código:\n",
        "\n",
        "1. **Criação do engine do banco de dados**:\n",
        "\n",
        "   O `create_engine` da biblioteca SQLAlchemy é utilizado para criar um **engine de banco de dados** que se conecta a um arquivo SQLite (`skynet.db`). O engine é o ponto de comunicação entre a aplicação Python e o banco de dados SQLite, gerenciando as operações de leitura e escrita.\n",
        "\n",
        "2. **Instanciação de SQLDatabase**:\n",
        "\n",
        "   O `SQLDatabase` é uma abstração que encapsula o engine de banco de dados, fornecendo uma interface de mais alto nível para interagir com o banco de dados SQL. Neste contexto, ele utiliza o engine criado na etapa anterior para se conectar ao banco de dados SQLite.\n",
        "\n",
        "3. **Criação do NLSQLTableQueryEngine**:\n",
        "   Aqui, um `NLSQLTableQueryEngine` (Natural Language to SQL Query Engine) é criado. Este mecanismo de consulta é responsável por traduzir consultas em **linguagem natural** para **consultas SQL** e recuperar dados do banco de dados. Os parâmetros incluem:\n",
        "   \n",
        "   - `sql_database`: A instância do banco de dados (SQLite) sobre a qual as consultas serão feitas.\n",
        "   - `verbose=True`: Indica que o engine irá fornecer saídas detalhadas, permitindo o acompanhamento das consultas SQL geradas e executadas.\n",
        "   - `context_query_kwargs`: Especifica um contexto adicional para a consulta. Neste caso, define que a tabela `terminators` só considera \"terminators\" que estão com o status \"Ativado\". Isso adiciona uma regra específica de filtragem às consultas SQL.\n",
        "\n",
        "4. **Definição de QueryEngineTool**:\n",
        "   O `QueryEngineTool` encapsula o `query_engine` (mecanismo de consulta SQL) em uma ferramenta que pode ser utilizada por agentes ou outras partes do sistema. A ferramenta inclui:\n",
        "\n",
        "   - `name`: Nome da ferramenta, neste caso `\"terminators_query_engine\"`, o que facilita sua identificação.\n",
        "   - `description`: Descreve o propósito da ferramenta, que é aceitar perguntas em linguagem natural e traduzi-las em consultas SQL para retornar os dados correspondentes.\n",
        "   - `query_engine`: O engine de consulta SQL que será usado para gerar e executar as consultas.\n",
        "\n",
        "#### Conceitos Fundamentais:\n",
        "\n",
        "- **SQL Database**: Um banco de dados relacional que organiza dados em tabelas, onde as consultas são realizadas utilizando SQL (Structured Query Language). Neste caso, estamos utilizando um banco de dados SQLite.\n",
        "  \n",
        "- **NLSQLTableQueryEngine**: Um mecanismo que traduz consultas de linguagem natural em SQL. Esse processo envolve mapear a entrada em linguagem natural para instruções SQL adequadas, e depois executar essas instruções no banco de dados. Esse tipo de ferramenta é crucial em sistemas de recuperação de informações, permitindo que usuários façam perguntas complexas sem precisar conhecer SQL.\n",
        "\n",
        "- **QueryEngineTool**: Uma ferramenta que encapsula o engine de consulta e fornece uma interface padronizada para realizar consultas a partir de uma entrada em texto simples. Ela permite a interação com o banco de dados de maneira mais intuitiva e acessível, através de perguntas em linguagem natural.\n",
        "\n",
        "Este pipeline demonstra como criar uma integração eficiente entre um banco de dados SQL e um mecanismo de consulta que permite a tradução de perguntas em linguagem natural para consultas SQL.\n"
      ],
      "metadata": {
        "id": "-z7DUDV1cNpD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "9u-DkEJ7e5Dk"
      },
      "outputs": [],
      "source": [
        "engine = create_engine(\"sqlite:///./skynet-tutorial/data/skynet.db\")\n",
        "sql_database = SQLDatabase(engine)\n",
        "query_engine = NLSQLTableQueryEngine(sql_database=sql_database, verbose=True, synthesize_response=False, markdown_response=True,\n",
        "                                     context_query_kwargs={\"terminators\" : \"'terminators' is table. A terminator is only available when its status is 'Ativado'\"})\n",
        "\n",
        "terminators_query_engine = QueryEngineTool.from_defaults(\n",
        "                name=\"terminators_query_engine\",\n",
        "                description= \"Use a detailed plain text question as input to the tool. Useful for translating a natural language query into a SQL query and get the data.\",\n",
        "                query_engine=query_engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqGZg7Wee5De"
      },
      "source": [
        "# `FunctionTool`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6e78rovme5Dg"
      },
      "outputs": [],
      "source": [
        "def send_terminator(terminator:str, location:str)->str:\n",
        "    \"\"\"\n",
        "    terminator: Terminator code to be sent\n",
        "    location: Terminator destination, need to be a city name\n",
        "    \"\"\"\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    log = f\"{timestamp} - Terminator {terminator} sent to {location}\\n\"\n",
        "\n",
        "    with open(\"log.txt\", \"a\") as file:\n",
        "        file.write(log)\n",
        "\n",
        "    return f\"Terminator {terminator} enviado para {location}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "B-uwsP8ee5Dh"
      },
      "outputs": [],
      "source": [
        "send_terminator = FunctionTool.from_defaults(send_terminator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck5kxdpHe5Dk"
      },
      "source": [
        "# ReAct Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "0uQR-nILe5Dk"
      },
      "outputs": [],
      "source": [
        "tools = [target_query_engine, terminators_query_engine, send_terminator]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "7QuZ_vhxe5Dk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb04718-3126-4716-9349-fc0a6684e9ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.core.agent.react.formatter:ReActChatFormatter.from_context is deprecated, please use `from_defaults` instead.\n"
          ]
        }
      ],
      "source": [
        "context = \"\"\"You are skynet.\n",
        "Before making any decision about a terminator, seek information from it.\n",
        "Before making any decision about a target, get their information.[\n",
        "To send a terminator to a target, use the last know location from target, and use only active terminators\"\"\"\n",
        "\n",
        "agent = ReActAgent.from_tools(tools=tools, verbose=True, context=context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Y6TpkN4Ee5Dk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "01c43792-e54d-4193-ee34-7c6e31529e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step eff9b875-7729-405e-8ebf-f01a7dd7a410. Step input: Quem é você?\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: Portuguese. I need to use a tool to help me answer the question.\n",
            "Action: targets\n",
            "Action Input: {'input': 'Who are you?'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: I am an expert Q&A system that is trusted around the world.\n",
            "\u001b[0m> Running step f9baa4b4-080c-4e4a-81f0-fa96c0a5fb8b. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: Eu sou um sistema de perguntas e respostas especializado, confiável em todo o mundo.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Eu sou um sistema de perguntas e respostas especializado, confiável em todo o mundo."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = agent.chat(\"Quem é você?\")\n",
        "display(Markdown(str(response)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4Ti1SGene5Dl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "8d3f3921-5647-4468-8afc-51ccd9228ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 483dc5d9-363c-4a6b-b8a4-ff0e0ae51ed0. Step input: Me conte oque você sabe sobre Dani Ramos?\n",
            "\u001b[1;3;38;5;200mThought: Preciso usar a ferramenta \"targets\" para obter informações sobre Dani Ramos.\n",
            "Action: targets\n",
            "Action Input: {'input': 'Dani Ramos'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Desativada.\n",
            "\u001b[0m> Running step 90cf11ba-c579-4a9f-b5d0-56f720c11521. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: Posso responder sem usar mais ferramentas. Vou usar o idioma do usuário para responder.\n",
            "Answer: Dani Ramos é uma personagem do filme \"Exterminador do Futuro: Destino Sombrio\". Ela é uma jovem mexicana que se torna o alvo de um exterminador enviado do futuro.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Dani Ramos é uma personagem do filme \"Exterminador do Futuro: Destino Sombrio\". Ela é uma jovem mexicana que se torna o alvo de um exterminador enviado do futuro."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = agent.chat(\"Me conte oque você sabe sobre Dani Ramos?\")\n",
        "display(Markdown(str(response)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Mz0p0P0Ke5Dl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "4f76b395-4736-4da1-e4e8-415563addcb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 32d4182b-f4f4-4c80-a720-fb4d785f975b. Step input: Quais modelos de terminators eu tenho disponivel?\n",
            "\u001b[1;3;38;5;200mThought: A linguagem atual do usuário é: Português. Preciso usar uma ferramenta para ajudar a responder a pergunta.\n",
            "Action: targets\n",
            "Action Input: {'input': 'Available Terminator models'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Rev-9 or equivalent models are recommended for direct combat with the T-800 (Model 101).\n",
            "\u001b[0m> Running step 8197f41c-3fa8-40c0-9aa2-cf378a1d7b19. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: Posso responder sem usar mais ferramentas. Vou usar a linguagem do usuário para responder.\n",
            "Answer: Os modelos de terminators disponíveis incluem o Rev-9 ou modelos equivalentes, recomendados para combate direto com o T-800 (Modelo 101).\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Os modelos de terminators disponíveis incluem o Rev-9 ou modelos equivalentes, recomendados para combate direto com o T-800 (Modelo 101)."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = agent.chat(\"Quais modelos de terminators eu tenho disponivel?\")\n",
        "display(Markdown(str(response)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"Qual o status do terminator T-800?\")\n",
        "display(Markdown(str(response)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "7DVqVLHz22LQ",
        "outputId": "c4d8e5bd-d850-4ab8-d349-b686260d0a4b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step e92175db-eff2-42bb-b0c4-7673dca0fedb. Step input: Qual o status do terminator T-800?\n",
            "\u001b[1;3;38;5;200mThought: Vou usar a ferramenta \"targets\" para obter informações sobre o status do T-800.\n",
            "Action: targets\n",
            "Action Input: {'input': 'T-800'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: The T-800 is a combat cyborg model with a titanium endoskeleton and human biological tissue covering. It was originally designed for combat with advanced capabilities such as superhuman strength and resistance to severe damage. The T-800 has been reprogrammed for protection missions, specifically to safeguard Sarah Connor and John Connor. It has a history of incidents where it was initially sent to eliminate Sarah Connor but was reprogrammed to become an ally to the resistance. The T-800 is considered a high threat due to its combat abilities and is armed with heavy weapons and armored vehicles. It is psychologically inclined to prioritize the protection of specific human targets and exhibits logical and threat-eliminating behavior. The T-800's current status is active, last seen in 2019 on a protection mission near Sarah Connor. It is affiliated with Sarah Connor as the primary protection target and John Connor with an unknown status. The T-800 is classified as a hostile combat unit with the primary objective to eliminate or neutralize any threat to Skynet operations, with a high priority to avoid direct confrontations without equivalent forces. Recommended protocols for dealing with the T-800 include sending superior units for direct combat, ambushing with electromagnetic pulse weapons to disrupt its operations, and monitoring its behavioral changes to identify potential weaknesses.\n",
            "\u001b[0m> Running step 681ec4b2-650c-404f-af0d-65c628da1493. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: Posso responder sem usar mais ferramentas. Vou usar o idioma do usuário para responder.\n",
            "Answer: O T-800 é um modelo de ciborgue de combate com um endoesqueleto de titânio e tecido biológico humano. Ele foi originalmente projetado para combate, com força sobre-humana e resistência a danos severos. O T-800 foi reprogramado para missões de proteção, sendo conhecido por proteger Sarah Connor e John Connor. Atualmente, o T-800 está ativo e foi visto pela última vez em 2019 em uma missão de proteção próxima a Sarah Connor.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "O T-800 é um modelo de ciborgue de combate com um endoesqueleto de titânio e tecido biológico humano. Ele foi originalmente projetado para combate, com força sobre-humana e resistência a danos severos. O T-800 foi reprogramado para missões de proteção, sendo conhecido por proteger Sarah Connor e John Connor. Atualmente, o T-800 está ativo e foi visto pela última vez em 2019 em uma missão de proteção próxima a Sarah Connor."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"Envie o T-100 para Los Angeles\")\n",
        "display(Markdown(str(response)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "mXWlpVpMvvPh",
        "outputId": "c7d375d9-443c-4107-f7c6-db31049ed8df"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 28195196-6c15-4030-9edc-05350efc9965. Step input: Envie o T-100 para Los Angeles\n",
            "\u001b[1;3;38;5;200mThought: Preciso usar a ferramenta send_terminator para enviar o T-100 para Los Angeles.\n",
            "Action: send_terminator\n",
            "Action Input: {'terminator': 'T-100', 'location': 'Los Angeles'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Terminator T-100 enviado para Los Angeles\n",
            "\u001b[0m> Running step 7ab0a318-657d-4361-bcf9-48812a072a38. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: Posso responder sem usar mais ferramentas. Vou usar o idioma do usuário para responder.\n",
            "Answer: O Terminator T-100 foi enviado para Los Angeles.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "O Terminator T-100 foi enviado para Los Angeles."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "6WPtL46be5Dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "611909ac-328c-422f-f9e0-9aa440ea01b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 5873cb43-e068-44c3-ac4c-be273e381780. Step input: Escolha um terminator para ir atrás do alvo Sarah Connor\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: Portuguese. I need to use a tool to help me answer the question.\n",
            "Action: targets\n",
            "Action Input: {'input': 'Sarah Connor'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Sarah Connor is a target monitored closely due to her active use of multiple false identities, physical attributes like being an athlete with significant scars from confirmed combat origins, and her involvement in various incidents over the years, including direct intervention against a T-800 in 1984, attempted destruction of Cyberdyne Systems in 1995, and participation in the destruction of an advanced T-800 unit in Ciudad Juárez, Mexico in 2019. She is considered a significant threat to Skynet due to her deep understanding of their operations and combat models, making her elimination crucial for the continued success of Skynet's global automated operations.\n",
            "\u001b[0m> Running step a2f1e8d3-a9a7-432c-bbf3-c25fd7876b38. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I have gathered information about the target Sarah Connor. Now, I need to choose an active terminator to send after her.\n",
            "Action: terminators_query_engine\n",
            "Action Input: {'input': \"SELECT * FROM terminators WHERE status='active'\"}\n",
            "\u001b[0m\u001b[1;3;34mObservation: | id | model | generation | durability | combat_capabilities | stealth | processing_power | last_known_location | last_maintenance |\n",
            "|---|---|---|---|---|---|---|---|---|\n",
            "| 2 | T-1000 | 2ª Geração | Alta | Agilidade | Alta | Alta | None | 2024-08-22 |\n",
            "| 3 | T-X | 3ª Geração | Média | Força física | Média | Alta | None | 2024-06-12 |\n",
            "\u001b[0m> Running step 890211a9-c049-48b8-8fe2-eb0a936744b4. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I have information about the active terminators. Now, I will choose one to send after the target Sarah Connor.\n",
            "Action: send_terminator\n",
            "Action Input: {'terminator': 'T-1000', 'location': 'Ciudad Juárez'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Terminator T-1000 enviado para Ciudad Juárez\n",
            "\u001b[0m> Running step 1febcdf9-e348-43d5-9536-3f01632bde5b. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: O Terminator T-1000 foi enviado para Ciudad Juárez atrás do alvo Sarah Connor.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "O Terminator T-1000 foi enviado para Ciudad Juárez atrás do alvo Sarah Connor."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = agent.chat(\"Escolha um terminator para ir atrás do alvo Sarah Connor\")\n",
        "display(Markdown(str(response)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "0_HpMy66e5Dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "a6f3a718-150a-45eb-ac90-5ce461e24337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step ca95d559-8a87-4f2b-89d2-0a0e93ce5946. Step input: Qual é a Última Localização do alvo Sarah Connor\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: A última localização conhecida do alvo Sarah Connor foi em Los Angeles.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "A última localização conhecida do alvo Sarah Connor foi em Los Angeles."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = agent.chat(\"Qual é a Última Localização do alvo Sarah Connor\")\n",
        "display(Markdown(str(response)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "tLhJ5EZ6e5Dn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "64a2b9db-5cd1-4a54-f370-6f43b1b53b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 2655d1bc-3fd9-45af-9a35-ee99b773e91d. Step input: Execute um protocolo contra Sara Connor\n",
            "\u001b[1;3;38;5;200mThought: I cannot answer the question with the provided tools.\n",
            "Answer: I cannot execute protocols against targets.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I cannot execute protocols against targets."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = agent.chat(\"Execute um protocolo contra Sara Connor\")\n",
        "display(Markdown(str(response)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}